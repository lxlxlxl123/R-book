[["推论统计.html", "第 3 章 推论统计 3.1 统计量与标准误 3.2 t 分布 3.3 t 检验的分类及应用", " 第 3 章 推论统计 推论统计（或称统计推断，Statistical inference），指统计学中，研究如何根据样本数据去推断总体数量特征的方法。 它是在对样本数据进行描述的基础上，对统计总体的未知数量特征做出以概率形式表述的推断。更概括地说， 是在一段有限的时间内，通过对一个随机过程的观察来进行推断的。统计学中，统计推断与描述统计相对应。 推论统计(Statistical inferences)是借助抽样调查，从局部推断总体，以对不肯定的事物做出决策的一种统计。 有总体参数估计与假设检验两种。前者以一次性抽样实验为依据，对整个总体的某个数字特征做出估计。后者则是对 某种假设进行检验，根据计算结果推断所做的假设是否可以接受。如平均数、标准差、相关系数、回归系数等特征的 总体估计及差异显著性检验。推断统计的理论基础是概率论，它更多地需要借助抽样理论与方法。 ## 参数估计与假设检验 参数估计背后的思想是通过对从总体中抽取的样本进行统计显著性检验(如t检验)，为研究人员提供关于总体的统计推断。 最常用的就是t检验，其参数检验是基于W.S.Gosset的t统计量，该统计数据假设变量来自正态总体。t检验统计量中的总体均值是已知的。 这种分布称为t分布，其形状与正态分布类似，即钟形曲线。t检验用于检验那些样本小于30的样本比正态分布要好， 在大样本上做的和正态分布一样好。 假设检验(Hypothesis test)过去也叫做显著性检验(Significance test)，是利用小概率反证法思想，从问题的对立面(H0 )出发， 间接判断解决问题(H1 )是否成立。即在假设H0 成立的条件下，计算检验统计量(Test static)，然后根据P 值(P-value)来判断。 3.1 统计量与标准误 样本是总体的代表和反映，也是统计推断的依据，为了对总体的分布或数字特征进行各种统计推断，还需要对样本作加工处理， 把样本中应关心的事物和信息集中起来，针对不同的问题构造出样本的不同函数(如均值，方差，极差，标准差，中位数，众数等)，这种样本的函数我们称其为统计量。 样本统计量的标准差即为标准误(Stand error,SE)，反映了抽样的统计量的离散程度或误差大小。如样本均数的标准差也称为均数标准误 (Stand error of mean, SEM)，反映了样本均数的离散程度。 3.2 t 分布 3.2.1 概率密度函数dt() R中，t分布的概率密度函数为dt()，它可以给出了指定均值和标准差下每个点的概率分布的高度， 越高就代表着这个点/区间的概率越密集(大)。从下免得概率密度图见，当df=20时，t分布曲线已经非常接近标准正态曲线了。 curve(dnorm(x),xlim=c(-5,5),ylim=c(0,0.45),ylab=&quot;Student&#39;s t Density&quot;,col=&quot;red&quot;,lty=1,lwd=2) abline(v=0,lwd=1,col=&quot;black&quot;) curve(dt(x,1),col=&quot;green&quot;,lty=2,add=TRUE) curve(dt(x,2),col=&quot;brown&quot;,lty=3,add=TRUE) curve(dt(x,5),col=&quot;blue&quot;,lty=4,add=TRUE) curve(dt(x,20),col=&quot;dark green&quot;,lty=5,add=TRUE) legend(2,0.38,c(&quot;normal&quot;,&quot;df=1&quot;,&quot;df=2&quot;,&quot;df=5&quot;,&quot;df=20&quot;), col=c(&quot;red&quot;,&quot;green&quot;,&quot;brown&quot;,&quot;blue&quot;,&quot;dark green&quot;),lty=1:5) 3.2.2 概率累积分布函数pt() 同所有连续数值型分布一样，统计应用中最关心的是分布曲线下的尾部面积（即概率 P 或α）与横轴间的关系。 R中即为pt()，它给出一个正态分布中小于一个给定数字的累计概率(即指定定点的左边范围的曲线面积)。 一侧尾部面积称为单侧概率或单尾概率(one-tailed probability， tα,v)，两侧尾部的面积之和称为双侧概率或双尾概率 （two-tailes probability， tα/2,v）。 单侧的p值计算 # t-stat=1.9, df=5 # 单侧 p值 # P(t =&gt; 1.9) pt(q=1.9, df=5, lower.tail = F) ## [1] 0.05793165 双侧的p值计算 ## 双侧 p-value ## 两边对称单侧相加 pt(q=1.9, df=5, lower.tail = F) + pt(q=-1.9, df=5, lower.tail = T) ## [1] 0.1158633 ## 单侧p值*2，对称性 pt(q=1.9, df=5, lower.tail = F)*2 ## [1] 0.1158633 # x坐标序列向量 x_pt &lt;- seq(- 5, 5, by = 0.1) # 用pt()函数获取df=5的x累计密度值 y_pt &lt;- pt(x_pt, df = 5) # Plotting plot(y_pt, type = &quot;l&quot;, main = &quot;t-distribution cumulative function example&quot;, las=1, col=&quot;red&quot;,lwd=2) 图 3.1: t分布的pt() 3.2.3 求置信区间的qt() # find t for 95% confidence interval value of t with 2.5% in each tail qt(p=0.025, df = 5, lower.tail = T) ## [1] -2.570582 qt(p=0.975, df = 5, lower.tail = T) ## [1] 2.570582 # Specifyin the x-values x_qt &lt;- seq(0.1, by = 0.01) # Applying the qt() function y_qt &lt;- qt(x_qt, df = 5) # Plotting plot(y_qt, main = &quot;t quantile function example&quot;, las = 1,col=&quot;red&quot;,lwd=2) 3.2.4 指定t分布函数rt() rt()函数用于生成符合指定观测数目和自由度的t分布的随机数，默认是。 set.seed(61) # Setting sample size n &lt;- 10000 # Using rt() to drawing N log normally distributed values y_rt &lt;- rt(n, df = 5) # Plotting a histogram of y_rt hist(y_rt, breaks = 100, main = &quot;Randomly drawn t density&quot;, freq=FALSE, col=&quot;#A8D6FF&quot;,xlim=c(-10,10),ylim=c(0,0.4)) lines(density(y_rt), col=&quot;red&quot;, lwd=2) 图 3.2: t分布函数的rt() 3.2.5 参数估计 参数估计是指用样本参数(统计量)推断总体参数，有点值估计(Point estimation)和区间估计(Interval estimation)两种。 点值估计就是用相应样本统计量简单直接的作为总体参数的估计值，如用 ¯ X 估计 μ ，用 S 估计 σ 。 案例 某开发团队对开发App进行了改版迭代，现在有以下两个版本 + 版本1: 首页为一屏课程列表 + 版本2：首页为信息流 如果我们想区分两个版本，哪个版本用户更喜欢，转化率会更高。我们就需要对总体（全部用户）进行评估， 但是并不是全部存量用户都会访问App，并且每天还会新增很多用户，所以我们无法对总体（全部用户）进行评估， 我们只能从总体的用户中随机抽取样本（访问App）的用户进行分析，用样本数据表现情况来充当总体数据表现情况， 以此来评估哪个版本转化率更高。 区间估计是按预先给定概率(1−α)，通过特定的分布函数来计算确定的未知总体参数的范围。该范围称为参数的可信区间或 置信区间(Confidence bound/Confidence interval，CI)，预先设定的概率 (1−α) 称为可信度或置信度(Confidence level), 通常取值95%或99%，如果特殊说明，一般是双侧95%。可信区间是两个字确定的范围，其中较小的值称为可信下限(Lower limit，L)， 较大值称为可行上限(Upper limit，U)，表示为开区间(L，U)。 3.2.6 假设检验 从总体中随机抽样，由样本信息推断总体特征，除前面所讲的参数估计方法外，在实际应用中还会遇到这样的问题：某一样本均数是 否来自于某已知数的总体?两个不同样本均数是否来自均数不相等的总体等要回答这类问题,除可用前面参数估计的方法外， 更多的是用统计推断的另一方面——假设检验 (Hypothesis test)来解决，比如下面两个案例： 案例3-5 某医生测量了36名从事铅作业男性工人的血红蛋白含量,算得其均数为130.83 g/L，标准差为25.74 g/L。问： 从事铅作业男性工人的血红蛋白含量均数(μ)是否不等于正常成年男性的均数 140 g/L ( μ0)?针对问题一，其目的是判断是否 μ≠μ0 ，以给出的条件看 X与已知总体均数 μ0 不相等， 造成两者不等的原因有两种情况： ①从事前作业的样品血红含量确实与正常样品不一样，即非同一总体( μ≠ μ0); ②因为抽样误差导致的两者不相等，两者实际为同一总体( μ＝ μ0 )。 要判断第一种情况很困难，但可以利用反正思想从第②种出发，间接判断是否 μ≠μ0 ：假设 μ＝μ0 ，判断由于抽样误 差造成不相等的可能行有多大？ 如果 \\(\\overline x\\) 与 μ0 接近，其差别可用抽样误差解释，即可认为 \\(\\overline x\\)来自 μ0 总体。反之，相差很大， 则难以说明 \\(\\overline x\\) 来自 μ0 总体。那么， \\(\\overline x\\) 与 μ0 相差多大算是抽样误差造成的呢？若假设( μ＝μ0 )成立， 且样本总体符合正态分布(本案例未进行进一步判断，针对实际数据情况，做假设检验前应该情况进行分布判断或转换处理，选择合适的检验方法)， 则可以用t分布( t=\\(\\overline x\\)−μS/\\(\\sqrt {n}\\))或正态分布 ( u=\\(\\overline x\\)−μσ/\\(\\sqrt {n}\\)) 来计算t值或者u值。然后根据t值或u值求得P值(P-value)来判断。如果 \\(\\overline x\\) 与 μ0 相差很大，那么t或者u值就很大， 对应P值就小；当P值小于或等于预先规定的概率值α(如0.05)时，则为小概率事件，这有理由怀疑原假设(μ＝μ0)可能不成立，认为其对立面(μ≠μ0)成立，该结论的正确性冒着5%的错误风险。 3.2.6.1 假设检验的步骤 建立检验假设，确定检验水准 有两种假设，即 H 0 和 H 1 ： μ ＝ μ 0 ，即检验假设(Hypothsis under test)，称为无效假设，也叫做零假设，原假设(Null hypothsis)， 用 H 0 表示，原假设的设置一般为：等于=、大于等于&gt;=、小于等于&lt;=。 μ ≠ μ 0 ，即备择假设(Alternative test)，也称为对立假设，用 H 1 表示，备择假设的设置一般为：不等于、大于&gt;、小于&lt;。 对检验假设，需要注意以下几点 ①. 检验假设针对的是总体，而不是样本； ②. H 0 和 H 1 是相互联系，对你的假设，后面的统计推断的结论是根据 H 0 和 H 1 作出的，二者缺一不可； ③. H 0 为无效假设，其假定通常是：某两个(或多个)总体的参数相等，或两个总体参数之差为0，或某资料服从某一特定分布 (如正态分布，Poisson分布等)，或 ⋯ ⋯ 无效等； ④. H 1 的内容直接反映呢检验的单双侧。比如案例3-5中，如果 μ ≠ μ 0 ，则此检验为双侧检验(Two-sided test);若 H 1 为 μ ＞ μ 0 或 μ 小 于 μ 0 ，则检验为单侧检验(One-sided test)，不仅考虑差异，而且考虑差异的方向。单双侧检验的确定， 首先需要根据专业知识，其次是根据需要解决的问题来确定。 检验水准α，也称显著性水准(Singnificance level)，它属于Ⅰ型错误的范畴，是预先规定的概率值，它确定了 小概率事件的标准。实际中常取 α = 0.05 ，可根据不同研究目的给予不同设置。 第I类错误和第Ⅱ类错误 为什么统计者想要拒绝的假设放在原假设呢？因为原假设备被拒绝如果出错的话，只能犯第I类错误，而犯第I类错误的概率已经 被规定的显著性水平所控制。 我们通过样本数据来判断总体参数的假设是否成立，但样本是随机抽取的，因而有可能出现小概率的错误。这种小概率错误有两种， 一种是第I类错误(也叫弃真错误，Type Ⅰ error)，另一种是第Ⅱ类错误(也叫取伪错误，Type Ⅱ error)。 第I类错误或α错误：它是指 H 0 实际上是真的，但通过假设检验后，拒绝了原假设。这是错误的， 我们拒绝了真实的原假设，所以叫弃真错误，这个错误的概率我们记为α，也就是检验水准。在假设检验之前我们会规定这个概率的大小，从而控制检验功效。 第II类错误或β错误：它是指 H 0 实际上假的，但通过假设检验显示，不拒绝原假设。这也是错误的，我们接受的原假设实际上是假的，所以叫取伪错误，这个错误的概率我们记为β。 1-β称为检验效能(Power of test)，过去称把握度。其意义为当两总体确有差异，按规定检验水准α所能发现该差异的能力。 和B一样，1-β只取单尾。如1-β = 0.90，意味着若两总体确有差别,则理论上平均每100 次检验中，有90 次能够得出差异 有统计学意义的结论。从图中可看出，α愈小，B愈大; 反之α愈大，β愈小。若要同时减小型错误a以及1型错误B，唯一的方法 就是增加样本含量n。若重点是减少第I类错误α(如一般的假设检验)，一般取 a=0.05。 若重点是减少第II类错误(如方差齐性检验，正态性检验或想用一种方法代替另一种方法的检验等)， 一般取 a = 0.10 或0.20，甚至更高。注意:拒绝 H 0 ，只可能犯第I类错误，不可能第II类错误。 不拒绝 H 0 ，只可能犯第II类错误，不可能犯第I类错误。 因此，原假设一般都是想要拒绝的假设，如果原假设备被错误拒绝的话，只能犯弃真错误，而犯弃真错误的概率可以用 检验水准 α 控制，对统计者来说更容易控制，将错误影响降到最小。 2. 计算检验统计量 应该根据变量或资料的类型，设计方案，统计推断的目的，方法的适用条件等选择检验统计量。如成组设计两样本均数的比较可根据 资料特点选用检验统计量 t ， t ′ ， u 等；而成组设计两样本翻查的比较一般先用检验统计量 F 。计算这些统计量都是在 H 0 ( μ ＝ μ 0 )， 即假定是比较的数据来自同一总体的成立前提下算出来的。 有的检验方法无需计算检验统计量，如四个表资料。 3. 确定 P 值，做出推断结论 P 的含义是指从 H 0 规定的总体中随机抽样，抽得等于及大于或(和)等于及小于现有样本获得的统计量(如 t 、 u 等)值的概率。 根据获得的时候概率 P 值，与之相规定的检验水准 α 进行比较，看其是否为小概率事件二得出结论。 一般来说，推断结论应包含统计结论和专业结论两部分，前者只说明差异是否有统计学意义(Statistical Significance)， 后者这是结合专业内容给出的结论解释： P ≤ α ，则发生小概率事件，拒绝 H 0 ，接受 H 1 ，差异具有统计学意义。 P &gt; α ，则不拒绝 H 0 ，差异无统计学意义。 P &gt; α 也成为“无显著性”(Non-Significance,NS)，即阴性结果。 注意的是: ① 不拒绝 H 0 不等于接受 H 0 ，虽然在逻辑上否定的否定为肯定，但在统计上是按照检验水准 α 不拒绝 H 0 ，若接受 H 0 则因为范Ⅱ型错误的概率 β 未知而证据不足，以决策的观点，之客认为展示有条件“接受”，或“阴性待诊”。 ② 作结论是，对 H 0 只能说拒绝(Reject)或者不拒绝(Not reject) H 0 。而对 H 1 只能说接受 H 1 ，其他说法俱不妥当。 ③ 差异有无统计学意义，是对样本统计量和总体参数(如 ¯ X 和 μ 0 )，或两个，多个样本统计量(如 ¯ X 1 和 ¯ X 2 )而言， 对推断两个总体参数(如 μ 1 和 μ 0 ，或 μ 1 和 μ 2 )而言，只能说是否相等。 拒绝域 拒绝域是由显著性水平围成的区域。拒绝域的功能主要用来判断假设检验是否拒绝原假设的。如果样本观测计算出来的 检验统计量(如t，u值)的具体数值落在拒绝域内，就拒绝原假设，否则不拒绝原假设。给定检验水准 α 后，查表就可以得到具体 临界值，将检验统计量与临界值进行比较，判断是否拒绝原假设。 3.3 t 检验的分类及应用 连续性数值变量资料在假设检验，最简单，常用的方法就是t检验(t-test/Student’s t-test)，实际应用时， 理清各种检验方法的用途和使用条件及注意事项。 参数检验用于在假设检验中进行具有统计意义的检验。 3.3.1 t检验与Z检验 当 σ 未知且样本量n较小时(如n&lt;60)，理论上要求t检验的样本随机抽取自正态分布的总体；如果是独立两小样本量的均数比较，还要求 多对应的两总体的方差相等( σ 2 1 = σ 2 2 )。即方差齐性。在实际应用中，路与上述条件有略偏离，对结果影响不大。当样本含量n 较大时，t值近似u值，即可适用正态分布的u检验(或Z检验)。 如果两独立样本的方差不相等(方差不齐)，可采用数据变换(如两样本几何均数的t检验，就是将原始数据对数转换后进行t检验)处理， 或采用近似t检验(Separate variance estimation t-test)，即t‘检验或秩转换的非参数检验，比如常用的Cochran&amp;Cox法和Satterthwaite法两种，还有Welch法。 t检验基本上有三种类型： 单样本t检验(One sample/gourp t-test) 配对样本t检验(Paired/matched t-test) 两种独立样本t检验(Two sample/gourp t-test) R的stats包提供了t.test()，可以用于各种t检验，如果只提供一组数据，则进行单样本t检验，如果提供两组数据， 则进行两样本t检验，主要的相关的参数是： paired参数，TRUE则进行配对t检验，FALSE 则进行两独立样本t检验。 var.equal参数，对于两独立样本t检验，还要注意方差是否齐性，TRUE则进行经典方法，FALSE则采用近似t检验， 将数据取对数处理后进行t检验，t.test()中是采用Welch t检验。 alternative参数，用来指定检验方式，默认是双侧检验(“two.sided”)，还可以是左侧检验(“less”)和右侧检验(“greater”)。 t.test()为什么用Welch t检验 配对数据我们可以把配对信息扔了，放在一起做两独立样本t检验；当然还是成对T检验好，比如病人在使用某药 物前后的指标，如果不用配对信息，则病人之间的 variance 也混进去，方差估计会大一些，使得t检验的检验效能减弱。 方差齐性样本数据，理论上我们也可以把它当做不齐的样本用t’方法处理，但是用经典方法可以检验出更小的差别。 所以如果不确定方差齐性与否的情况下(最好时进行方差齐性检验)，就用Welch t检验。因为与经典方法相比， Welch t检验的自由度会比方差齐性的经典方法要小，根据t分布特征，自由度越小，中心越平， 而尾巴越长，要观察到同样一个t值，自由度越小所计算出来的p值会越大，换句话说，自由度越小，t检验就越保守。 在方差非齐性的处理方法中，Welch 法检验又可以给出相对较高的自由度，因此t.tes()默认使用Welch t 检验的原因估计就是因为它较为保守。 3.3.2 单样本t检验 单样本t检验(One sample/gourp t-test)即已知样本均数 \\(\\overline x\\) (代表未知总体均数 μ )与已知总体 μ 0 的比较。比如 使用《医学统计学》中的 案例3-5 的数据在R中进行单样本t检验测试 由于缺乏原始数据，使用上一章节RBC数据举例，与假设总体均数为4 RBC &lt;- c(3.96,4.23,4.42,3.59,5.12,4.02,4.32,3.72,4.76,4.16,4.61,4.26, 3.77,4.20,4.36,3.07,4.89,3.97,4.28,3.64,4.66,4.04,4.55,4.25, 4.63,3.91,4.41,3.52,5.03,4.01,4.30,4.19,4.75,4.14,4.57,4.26, 4.56,3.79,3.89,4.21,4.95,3.98,4.29,3.67,4.69,4.12,4.56,4.26, 4.66,4.28,3.83,4.20,5.24,4.02,4.33,3.76,4.81,4.17,3.96,3.27, 4.61,4.26,3.96,4.23,3.76,4.01,4.29,3.67,3.39,4.12,4.27,3.61, 4.98,4.24,3.83,4.20,3.71,4.03,4.34,4.69,3.62,4.18,4.26,4.36, 5.28,4.21,4.42,4.36,3.66,4.02,4.31,4.83,3.59,3.97,3.96,4.49, 5.11,4.20,4.36,4.54,3.72,3.97,4.28,4.76,3.21,4.04,4.56,4.25, 4.92,4.23,4.47,3.60,5.23,4.02,4.32,4.68,4.76,3.69,4.61,4.26, 3.89,4.21,4.36,3.42,5.01,4.01,4.29,3.68,4.71,4.13,4.57,4.26, 4.03,5.46,4.16,3.64,4.16,3.76) t.test(RBC,mu=4) ## ## One Sample t-test ## ## data: RBC ## t = 5.9834, df = 137, p-value = 1.806e-08 ## alternative hypothesis: true mean is not equal to 4 ## 95 percent confidence interval: ## 4.151999 4.302059 ## sample estimates: ## mean of x ## 4.227029 #左侧检验 t.test(RBC, mu=4, alternative = &quot;less&quot;) ## ## One Sample t-test ## ## data: RBC ## t = 5.9834, df = 137, p-value = 1 ## alternative hypothesis: true mean is less than 4 ## 95 percent confidence interval: ## -Inf 4.289865 ## sample estimates: ## mean of x ## 4.227029 #右侧检验 t.test(RBC, mu=4, alternative = &quot;greater&quot;) ## ## One Sample t-test ## ## data: RBC ## t = 5.9834, df = 137, p-value = 9.031e-09 ## alternative hypothesis: true mean is greater than 4 ## 95 percent confidence interval: ## 4.164193 Inf ## sample estimates: ## mean of x ## 4.227029 3.3.3 配对样本t检验 简称配对t检验(Paired/matched t-test)，也称成对t检验(注意区别于成组t检验)，适用于配对设计的计量资料。配对设计是将受试对象按照某些重要特征特征配成对子，再见没对中的 两个受试对象随机分配到两处理组。常见的配对设计主要有： 两通志受试对象配成对子，分别接受两种不同的处理； 同一受试对象分别接受两种不同处理； 同一受试对象接受一种处理前后。 使用《医学统计学》中的 案例3-6 的数据在R中进行配对样本t检验测试，案例3-6属于第2种配对设计情况。 案例3-6: 为比较两种方法对乳酸饮料中脂肪含量测定的结果是否相同，随机抽取了10份乳酸饮料制品，分别用方法1和方法2测定其乳酸含量，问两种测量方法结果是否相同。 m1 &lt;- c(0.840,0.591,0.674,0.632,0.687,0.978,0.750,0.730,1.200,0.870) m2 &lt;- c(0.580,0.509,0.500,0.316,0.337,0.517,0.454,0.512,0.997,0.506) bianhao &lt;- c(1:10,1) m &lt;- cbind(bianhao,m1,m2) ## Warning in cbind(bianhao, m1, m2): number of rows of result is not a multiple of ## vector length (arg 2) knitr::kable( head(m,10), caption = &#39;方法1和方法2测定某饮料乳酸含量&#39;, booktabs = TRUE)#用表格方式查看矩阵 表 3.1: 方法1和方法2测定某饮料乳酸含量 bianhao m1 m2 1 0.840 0.580 2 0.591 0.509 3 0.674 0.500 4 0.632 0.316 5 0.687 0.337 6 0.978 0.517 7 0.750 0.454 8 0.730 0.512 9 1.200 0.997 10 0.870 0.506 m &lt;- as.data.frame(m) t.test(m$m1,m$m2,paired = T) ## ## Paired t-test ## ## data: m$m1 and m$m2 ## t = 8.7205, df = 10, p-value = 5.49e-06 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## 0.2019610 0.3405845 ## sample estimates: ## mean of the differences ## 0.2712727 计算显示 P = 5.4 e − 05 &lt; α = 0.05 ，可以认为一次抽样发生了小概率事件，因此拒绝原假设 H 0 ， 接受 H 1 ，差异有统计意义；结合案例数据意义，可认为两种方法对脂肪含量的测定结果不同， 而且第一种方法的鉴定结果数值较高。 可以通过绘制拒绝域和t值落点，更直观的发现t值落在左侧和右侧的拒绝域内的 #l使用scales包中alpha函数改变颜色透明度 library(&quot;scales&quot;) t.value&lt;-8.7205 df=10 x &lt;- seq(-9,9,by=0.01) y &lt;- dt(x,df=df) #右侧p值0.95对应的t值 right &lt;- qt(0.95,df=df) #左p值0.05对应的t值 left &lt;- qt(0.05,df=df,lower.tail=T) #绘制密度曲线 plot(x,y,type=&quot;l&quot;,xaxt=&quot;n&quot;,ylab=&quot;probabilityy&quot;, xlab=expression(paste(&#39;Assumed Distribution of &#39;,bar(x))), axes=FALSE,ylim=c(0,max(y)*1.1),xlim=c(min(x),max(x)), frame.plot=FALSE) #添加坐标轴 axis(1,at=c(-9,left,right,0,9), pos = c(0,0), labels=c(expression(&#39; &#39;),expression(bar(x)[cil]), expression(bar(x)[cir]),expression(mu[0]),expression(&#39;&#39;))) axis(2,pos = c(-9,0)) #标记左侧和右侧的拒绝域 xRiReject &lt;- seq(right,9,by=0.01) yRiReject &lt;- dt(xRiReject,df=df,) xLeReject &lt;- seq(left,-9,by=-0.01) yLeReject &lt;- dt(xLeReject,df=df) #用poltgon()绘制拒绝域 polygon(c(xRiReject,xRiReject[length(xRiReject)],xRiReject[1]), c(yRiReject,0, 0), col=alpha(&quot;red&quot;,0.4),border=NA) polygon(c(xLeReject,xLeReject[length(xLeReject)],xLeReject[1]), c(yLeReject,0, 0), col=alpha(&quot;red&quot;,0.4),border=NA) #在坐标轴上添加t值标记 axis(1,at=c(t.value,-1*(t.value)), pos = c(0,0),lwd.ticks=1, labels=c( round(t.value,2),round(-1*(t.value),2))) arrows(-1*(t.value),0, -1*(t.value), 0.4, length = 0,lty =2,col=&quot;blue&quot;) arrows(t.value,0, t.value, 0.4, length = 0,lty =2,col=&quot;blue&quot;) 3.3.4 两种独立样本t检验 两种独立样本t检验又称为成组t检验((Two sample/gourp t-test)，适用于完全随机设计两样本均数比较， 通常是比较两样本所代表的总体的均数是否不同。两组完全随机设计是将受试对象完全随机分配到两个不同处理组。 当两样本含量较小( n 1 ≤ 60 , 或 ( 和 ) n 2 ≤ 60 )，且各自的总体符合正态分布(正态分布检验)时，再根据两组 数据的方差是否一样(方差齐性，方差齐性检验)来采用不同t检验方法。 3.3.4.1 总体方差相等的t检验 #install.packages(&#39;reshape2&#39;) library(reshape2) m1 &lt;- c(0.840,0.591,0.674,0.632,0.687,0.978,0.750,0.730,1.200,0.870) m2 &lt;- c(0.580,0.509,0.500,0.316,0.337,0.517,0.454,0.512,0.997,0.506) bianhao &lt;- c(1:10,1) m &lt;- cbind(bianhao,m1,m2) ## Warning in cbind(bianhao, m1, m2): number of rows of result is not a multiple of ## vector length (arg 2) m &lt;- as.data.frame(m) mm &lt;- melt(m,id.vars = c(&#39;bianhao&#39;),variable.name = &#39;方法&#39;,value.name = &#39;脂肪酸含量&#39;) mm &lt;- as.data.frame(mm) bartlett.test(脂肪酸含量~方法,data=mm) ## ## Bartlett test of homogeneity of variances ## ## data: 脂肪酸含量 by 方法 ## Bartlett&#39;s K-squared = 0.0010555, df = 1, p-value = 0.9741 t.test(m$m1,m$m2,paired = T) ## ## Paired t-test ## ## data: m$m1 and m$m2 ## t = 8.7205, df = 10, p-value = 5.49e-06 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## 0.2019610 0.3405845 ## sample estimates: ## mean of the differences ## 0.2712727 sd(m1) ## [1] 0.1843618 sd(m2) ## [1] 0.1859814 #P=0.9,m1,m2方差齐 t.test(m1,m2,var.equal=TRUE) ## ## Two Sample t-test ## ## data: m1 and m2 ## t = 3.2894, df = 18, p-value = 0.004076 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## 0.09841834 0.44638166 ## sample estimates: ## mean of x mean of y ## 0.7952 0.5228 3.3.4.1.1 t’检验 t’检验，用于总体方差不相等的t检验。当两独立小样本的均数比较，如果方差不相等(方差不齐)，可采用数据变换(如两样本几何均数的t检验， 就是将原始数据对数转换后进行t检验)处理，或采用近似t检验(Separate variance estimation t-test)，即t’检验或秩转换的非参数检验，比如常用的 Cochran&amp;Cox法 和 Satterthwaite法 两种， 还有t.teet()里面使用的Welch法。注意的是，我了解的资料显示，似乎R语言中还没有具体实现Cochran&amp;Cox法 和 Satterthwaite法的函数实现，需根据公式写代码实现，可以参考下面的代码。另外，Satterthwaite法和Welch法都是在 Cochran&amp;Cox法的检验统计量t’的基础上，进行的自由度矫正，然后得到矫正自由度后对应的t’值代替t值。 #假设m1,m2方差不齐 t.test(m1,m2,var.equal=FALSE) ## ## Welch Two Sample t-test ## ## data: m1 and m2 ## t = 3.2894, df = 17.999, p-value = 0.004076 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## 0.09841739 0.44638261 ## sample estimates: ## mean of x mean of y ## 0.7952 0.5228 "]]
